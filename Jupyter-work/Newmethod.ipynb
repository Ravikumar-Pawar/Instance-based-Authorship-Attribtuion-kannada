{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New method using TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from pip._internal.utils.misc import tabulate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import glob\n",
    "import pandas as pd\n",
    "%run stylometric_Features.ipynb import FeatureExtration\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import warnings\n",
    "import string\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.svm import SVC\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_instances={\n",
    "\n",
    "'hrudayashiva':[\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",10,11,12],\n",
    "    'ravibeliger':[13,14,15,16,17,18,19,20,21,22,23,24,25],\n",
    "    'somashaker':[26,27,28,29,30,31,32,33,34,35,36],\n",
    "    'Other author':[]\n",
    "}\n",
    "#from features_NormalApproach import FeatureExtration\n",
    "\n",
    "\n",
    "stop_words_list = \"C://Users/RAVIKUMAR/PycharmProjects/Authorship_Attribution_Instance/Data_2/new_stop_words.txt\"\n",
    "data_folder = \"C://Users/RAVIKUMAR/PycharmProjects/Authorship_Attribution_Instance/Data_2/train\"\n",
    "instance_by_author={}\n",
    "for author,AllFiles_Per_author in all_instances.items():\n",
    "    for i in AllFiles_Per_author:\n",
    "        for name in glob.glob(f\"C://Users/RAVIKUMAR/PycharmProjects/Authorship_Attribution_Instance/Data_2/train/instance{i}.txt\"):\n",
    "            with open(name, encoding='utf-8') as file:\n",
    "                instance_by_author[author+str(i)]=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lemmatiser = WordNetLemmatizer()\n",
    "stopword=[]\n",
    "with open(stop_words_list, encoding='utf-8') as file:\n",
    "    reader=file.read()\n",
    "    stopword.append(reader)\n",
    "\n",
    "def text_process(tex):\n",
    "    nopunct = [char for char in tex if char not in string.punctuation]\n",
    "    nopunct = ''.join(nopunct)\n",
    "    a = ''\n",
    "    for i in range(len(nopunct.split())):\n",
    "        b = lemmatiser.lemmatize(nopunct.split()[i], pos=\"v\")\n",
    "        a = a + b + ' '\n",
    "    return [word for word in a.split() if not word in stopword]\n",
    "all_authors=[]\n",
    "text=[]\n",
    "for author, file in instance_by_author.items():\n",
    "    all_authors.append(author)\n",
    "    text.append(file)\n",
    "    text_process(file)\n",
    "\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['author']=all_authors\n",
    "df['author'][0:13]='hrudayashiva'\n",
    "df['author'][13:25]='ravibeligeri'\n",
    "df['author'][25:36]='somashaker'\n",
    "df['text']=text\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for author, file in instance_by_author.items():\n",
    "#     df['Sylometric']=pd.Series(FeatureExtration(file))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = df['author']\n",
    "# labelencoder = LabelEncoder()\n",
    "# y = labelencoder.fit_transform(y)\n",
    "X = df['text']\n",
    "df.index=df.index+1\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 80-20 splitting the dataset (80%->Training and 20%->Validation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#defining the bag-of-words transformer on the text-processed corpus # i.e., text_process() declared in II is executed...\n",
    "#bow_transformer=CountVectorizer(ngram_range=(2,3),min_df=5, analyzer=text_process).fit(X_train)\n",
    "word_vector=TfidfVectorizer(analyzer=\"word\", ngram_range=(2,3),max_features=2000, binary=False).fit(X_train)\n",
    "word_vector1=TfidfVectorizer(analyzer=\"word\", ngram_range=(3,4),max_features=2000, binary=False).fit(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "char_vector=TfidfVectorizer(analyzer=\"char\", ngram_range=(2,3),max_features=2000, binary=False,min_df=3).fit(X_train)\n",
    "char_vector1=TfidfVectorizer(analyzer=\"char\", ngram_range=(3,3),max_features=2000, binary=False,min_df=3).fit(X_train)\n",
    "bow_transformer=FeatureUnion([ (\"chars\",char_vector),(\"word\",word_vector),(\"3_chars\",char_vector1),(\"3_word\",word_vector1)] )\n",
    "\n",
    "\n",
    "#bow_transformer =  TfidfVectorizer(min_df=3, analyzer=text_process).fit(X_train)\n",
    "\n",
    "#bow_transformer=FeatureExtration(X_train)\n",
    "#transforming into Bag-of-Words and hence textual data to numeric..\n",
    "feature_names = bow_transformer.get_feature_names()\n",
    "text_bow_train=bow_transformer.transform(X_train)#ONLY TRAINING DATA\n",
    "\n",
    "# transforming into Bag-of-Words and hence textual data to numeric..\n",
    "text_bow_test=bow_transformer.transform(X_test)#TEST DATA\n",
    "\n",
    "\n",
    "#print(bow_transformer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<28x8000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 81340 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(\"num of features: \", (bow_transformer.get_feature_names()))\n",
    "text_bow_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of the model : 1.0\n",
      "testig score of the model 0.875\n",
      "                                                 text        author\n",
      "8   \\nಅದೊಂದು ಮಾಮೂಲಿ ದಿನ… ಆ ಸಂಜೆ ಒಂದು ಕಾರ್ಯಕ್ರಮಕ್ಕೆ...  hrudayashiva\n",
      "35  \\n \" ಇರುವುದೆಲ್ಲವ ಬಿಟ್ಟು ಇರದುದರೆಡೆಗೆ ತುಡಿವುದೇ ಜ...    somashaker\n",
      "13  ಇತ್ತೀಚೆಗೊಂದು ಮಧ್ಯಾಹ್ನ ದಾವಣಗೆರೆಯಿಂದ ರವೀಂದ್ರನಾಥ್...  ravibeligeri\n",
      "1   ಪ್ರಖ್ಯಾತ ಹಿಂದೂಸ್ತಾನಿ ಸಂಗೀತಗಾರ ಪಂಡಿತ್ ಪರಮೇಶ್ವರ ...  ravibeligeri\n",
      "4   \\n'ಈ ಹಾಡನ್ನು ಬೇರೆ ಯಾರಿಂದಲಾದರೂ ಬರೆಸಿಬಿಡಿ ಪ್ಲೀಸ್...  hrudayashiva\n",
      "31  \\nಪ್ರಪಂಚ ರಹಸ್ಯಗಳ, ವಿಸ್ಮಯಗಳ ಆಗರ! ಎಲ್ಲಾ ಜೀವಿಗಳಂತ...    somashaker\n",
      "14  \\n“ಅಬ್ಬ! ಎಂ.ಎ.? ಎಷ್ಟು ಕೊಡ್ತಾರಲೆ?\" ಕಣ್ಣರಳಿಸಿ ಕೇ...  ravibeligeri\n",
      "27  \\nಮಾಂಗಲ್ಯಂ ತಂತುನಾನೇನ ಮಮಜೀವನ ಹೇತುನಾ … ಎಂಬ ಮಂತ್ರ...    somashaker\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1     \\nಹೋಳಿ ಹಬ್ಬದ ಸಂಭ್ರಮ, ಖುಷಿಗಳನ್ನು ನೀವೂ ಅನುಭವಿಸಿರ...\n",
       "2     ಪ್ರಖ್ಯಾತ ಹಿಂದೂಸ್ತಾನಿ ಸಂಗೀತಗಾರ ಪಂಡಿತ್ ಪರಮೇಶ್ವರ ...\n",
       "3     \\nಟಾಮ್ ಹಾಂಕ್ಸ್ ಕ್ಯಾಲಿಫೋರ್ನಿಯಾದ ಪ್ರತಿಭಾವಂತ. ಈತ ...\n",
       "4     \\nಹೆಂಡತಿಯು ಹದ ಮಾಡಿಕೊಟ್ಟ ತಾಂಬೂಲ ಜಗಿಯುತ್ತಲೇ ಅವರು...\n",
       "5     \\n'ಈ ಹಾಡನ್ನು ಬೇರೆ ಯಾರಿಂದಲಾದರೂ ಬರೆಸಿಬಿಡಿ ಪ್ಲೀಸ್...\n",
       "6     \\nನಾನು ಹದಿನಾರನೇ ವಯಸ್ಸಿಗೆ ಹಳ್ಳಿಗಳನ್ನು ಬಿಟ್ಟಿದ್ದ...\n",
       "7     \\nದೆವ್ವಗಳ ಬಗ್ಗೆ ಚರ್ಚಿಸುವುದೇ ವೇಳೆ ಹಾಳುಮಾಡಿಕೊಳ್ಳ...\n",
       "8     \\nಅನಂತಮೂರ್ತಿಯವರ ಕುರಿತು ಒಂದಿಷ್ಟು ಧ್ಯಾನಿಸುವ ಸಮಯವ...\n",
       "9     \\nಅದೊಂದು ಮಾಮೂಲಿ ದಿನ… ಆ ಸಂಜೆ ಒಂದು ಕಾರ್ಯಕ್ರಮಕ್ಕೆ...\n",
       "10    \\nದಟ್ಟ ಮೌನ ಕವಿದಿದೆ. ತಾತನ ಗೋರಿಯ ಪಕ್ಕದಲ್ಲಿ ಕುಳಿತ...\n",
       "11    \\nಕಗ್ಗಲಿಪುರದಲ್ಲಿ 'ಕರುನಾಡ ಗಜಕೇಸರಿ ಸೇನೆ'ಯ ಉದ್ಘಾಟ...\n",
       "12    \\n\\nಅದೇಕೋ ನೆನಪಾಗುತ್ತಿದೆ. ಐದಾರು ವರ್ಷಗಳ ಹಿಂದೆ ನಾ...\n",
       "13    \\nಆಕೆ ಟಿಕೆಟ್ ಕೌಂಟರ್‌ನ ಮುಂದೆ ನಿಂತು ಸಿನೆಮಾ ಚೆನ್ನ...\n",
       "14    ಇತ್ತೀಚೆಗೊಂದು ಮಧ್ಯಾಹ್ನ ದಾವಣಗೆರೆಯಿಂದ ರವೀಂದ್ರನಾಥ್...\n",
       "15    \\n“ಅಬ್ಬ! ಎಂ.ಎ.? ಎಷ್ಟು ಕೊಡ್ತಾರಲೆ?\" ಕಣ್ಣರಳಿಸಿ ಕೇ...\n",
       "16    \\nಇವತ್ತು ಮಂಜು, ಸುಮಿತ್ರ, ಶಶಿಧರ ಎಲ್ಲರೂ ಬೆಂಗಳೂರಿನ...\n",
       "17    \\nಗೆಳೆಯರು ಅವನನ್ನೇ ಆಶ್ಚರ್ಯದಿಂದ ನೋಡಿದರು. ಟೇಬಲ್‌ನ...\n",
       "18    \\nಈ ಹುಡುಗ ಸುದೀಪ್.\\n\\nಆತನ ಬಗ್ಗೆ ನನಗೊಂದು ಪ್ರೀತಿಯ...\n",
       "19    \\nಅವರೊಂದಿಗಿನ ನನ್ನ ಸ್ನೇಹ ಸುಮಾರು ಇಪ್ಪತ್ತು ವರ್ಷಗಳ...\n",
       "20    \\nಕ್ಲಾಸಿನಲ್ಲಿರೋದೇ ಮೂರೂ ಮುಕ್ಕಾಲು ಜನ. ಅವರ ಪೈಕಿಯೇ...\n",
       "21    ಜಾತಿಗಾ? ಮಾತಿಗಾ? ಅಷ್ಟು ದೊಡ್ಡ ಸಾಧಕರು ಅವರು. ಇನ್ನೇ...\n",
       "22    ಅದಕ್ಕೆ ಯಾಕೆ ನಾನು ಹಾಗೆ ಹೆಸರಿಟ್ಟೆನೋ ಗೊತ್ತಿಲ್ಲ. ಆ...\n",
       "23    \\nಹಾಗಂತ ಆಣೆ ಮಾಡಿ ಮನೆಯಿಂದ ಹೊರಬಿದ್ದಿರಬೇಕು ವಿಶ್ವೇ...\n",
       "24    \\nನಾನೊಂದು ಹೊಸ ಕಾರು ತೆಗೊಂಡೆ, ನಮ್ಮನೆ ಬೆಕ್ಕು ಮರಿ ...\n",
       "25    \\nದೇಶದ ಹಲವು ರಾಜ್ಯಗಳಲ್ಲಿ ಆತ್ಮಹತ್ಯೆ ಮಾಡಿಕೊಳ್ಳುತ್...\n",
       "26    \\nಮನಸ್ಸು ಅದ್ಭುತವಾದುದು! ಅತ್ಯದ್ಬುತವಾದುದು! ಯಾರೂ ಅ...\n",
       "27    \\nಬಹಳ ವರುಷ ಒಂದೇ ಸ್ಥಳದಲ್ಲಿ, ಒಂದೇ ವಾತಾವರಣದಲ್ಲಿ ವ...\n",
       "28    \\nಮಾಂಗಲ್ಯಂ ತಂತುನಾನೇನ ಮಮಜೀವನ ಹೇತುನಾ … ಎಂಬ ಮಂತ್ರ...\n",
       "29    \\nಜೀವನದಲ್ಲಿ ಮಾನವ ಅನೇಕ ಮುಖ್ಯ ಘಟ್ಟಗಳನ್ನು ದಾಟುತ್ತ...\n",
       "30    \\nದಿನ ಪತ್ರಿಕೆಯ ಪುಟಗಳನ್ನು ತಿರುವಿ ಹಾಕಿದರೆ ಒಂದೆರಡ...\n",
       "31    \\nಕನಸುಗಳು ಮನುಷ್ಯನನ್ನು ಪ್ರಾಚೀನ ಕಾಲದಿಂದಲೂ ವಿಸ್ಮಯ...\n",
       "32    \\nಪ್ರಪಂಚ ರಹಸ್ಯಗಳ, ವಿಸ್ಮಯಗಳ ಆಗರ! ಎಲ್ಲಾ ಜೀವಿಗಳಂತ...\n",
       "33    \\nಮಾನವನ ಬದುಕು ಸಾರ್ಥಕ ಆಗಬೇಕಾದರೆ ಅವನು ಏನನ್ನಾದರೂ ...\n",
       "34    \\nಬದಲಾವಣೆ ಜಗದ ನಿಯಮ! ಪ್ರಕೃತಿ ನಿತ್ಯನೂತನ. ನವನವೀನ!...\n",
       "35    \\nಅರಿಷಡ್ವರ್ಗಗಳು ಮಾನವನನ್ನು ಉತ್ತಮನಾಗಲಿಕ್ಕೆ ಬಿಡುವ...\n",
       "36    \\n \" ಇರುವುದೆಲ್ಲವ ಬಿಟ್ಟು ಇರದುದರೆಡೆಗೆ ತುಡಿವುದೇ ಜ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "# instantiating the model with Multinomial Naive Bayes..\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "# training the model...\n",
    "model = model.fit(text_bow_train, y_train)\n",
    "#import\n",
    "print(\"score of the model :\",model.score(text_bow_train, y_train))\n",
    "print(\"testig score of the model\",model.score(text_bow_test, y_test))\n",
    "\n",
    "# Importing necessary libraries\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# getting the predictions of the Validation Set...\n",
    "\n",
    "predictions = model.predict(text_bow_test)\n",
    "pred = pd.DataFrame()\n",
    "pred[\"text\"] = X_test\n",
    "pred[\"author\"]=predictions\n",
    "print(pred)\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data\n",
      "  8     \\nಅದೊಂದು ಮಾಮೂಲಿ ದಿನ… ಆ ಸಂಜೆ ಒಂದು ಕಾರ್ಯಕ್ರಮಕ್ಕೆ...\n",
      "35    \\n \" ಇರುವುದೆಲ್ಲವ ಬಿಟ್ಟು ಇರದುದರೆಡೆಗೆ ತುಡಿವುದೇ ಜ...\n",
      "13    ಇತ್ತೀಚೆಗೊಂದು ಮಧ್ಯಾಹ್ನ ದಾವಣಗೆರೆಯಿಂದ ರವೀಂದ್ರನಾಥ್...\n",
      "1     ಪ್ರಖ್ಯಾತ ಹಿಂದೂಸ್ತಾನಿ ಸಂಗೀತಗಾರ ಪಂಡಿತ್ ಪರಮೇಶ್ವರ ...\n",
      "4     \\n'ಈ ಹಾಡನ್ನು ಬೇರೆ ಯಾರಿಂದಲಾದರೂ ಬರೆಸಿಬಿಡಿ ಪ್ಲೀಸ್...\n",
      "31    \\nಪ್ರಪಂಚ ರಹಸ್ಯಗಳ, ವಿಸ್ಮಯಗಳ ಆಗರ! ಎಲ್ಲಾ ಜೀವಿಗಳಂತ...\n",
      "14    \\n“ಅಬ್ಬ! ಎಂ.ಎ.? ಎಷ್ಟು ಕೊಡ್ತಾರಲೆ?\" ಕಣ್ಣರಳಿಸಿ ಕೇ...\n",
      "27    \\nಮಾಂಗಲ್ಯಂ ತಂತುನಾನೇನ ಮಮಜೀವನ ಹೇತುನಾ … ಎಂಬ ಮಂತ್ರ...\n",
      "Name: text, dtype: object \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "hrudayashiva       1.00      0.67      0.80         3\n",
      "ravibeligeri       0.67      1.00      0.80         2\n",
      "  somashaker       1.00      1.00      1.00         3\n",
      "\n",
      " avg / total       0.92      0.88      0.88         8\n",
      "\n",
      "Enter the string\n",
      "ಮಾಂಗಲ್ಯಂ ತಂತುನಾನೇನ ಮಮಜೀವನ ಹೇತುನಾ … ಎಂಬ ಮಂತ್ರ\n",
      "{'hrudayashiva'}\n"
     ]
    }
   ],
   "source": [
    " print(\"test data\\n \",X_test,\"\\n\")\n",
    "# getting the Precision, Recall, F1-Score\n",
    "print(classification_report(y_test, predictions))\n",
    "#print(predictions,X_test)\n",
    "with open(\"NewFile.txt\",encoding=\"utf-8\") as unknown:\n",
    "    unknownFile=unknown.read()\n",
    "unknownFile2=input(\"Enter the string\\n\")\n",
    "df[\"NewData\"]=unknownFile2\n",
    "z_test=df[\"NewData\"]\n",
    "text_bow_test2=bow_transformer.transform(z_test)#TEST DATA\n",
    "\n",
    "predictions2=model.predict(text_bow_test2)\n",
    "s = set(predictions2)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
